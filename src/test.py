import os
import numpy as np
import pandas as pd
import joblib
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.metrics import MeanAbsoluteError  # for custom_objects

# ============================================================
# CONFIGURATION
# ============================================================
FEATURE_DIR = r"Y:\ML_CHALLENGE_2025\ml-pricing-challenge\features_combined"  # directory where features are stored
MODEL_PATH = r"Y:\ML_CHALLENGE_2025\ml-pricing-challenge\features\hybrid_model_trained.h5"

# ============================================================
# 1ï¸âƒ£ Load Precomputed Image Features
# ============================================================
print("ğŸ“‚ Loading precomputed image features...")
image_features_path = os.path.join(FEATURE_DIR, "image_features.npy")
if not os.path.exists(image_features_path):
    raise FileNotFoundError(f"âŒ {image_features_path} not found!")
image_features = np.load(image_features_path)
print(f"âœ… Image features loaded: {image_features.shape}")

# ============================================================
# 2ï¸âƒ£ Load Metadata
# ============================================================
metadata_path = os.path.join(FEATURE_DIR, "metadata.csv")
if not os.path.exists(metadata_path):
    raise FileNotFoundError(f"âŒ {metadata_path} not found!")

metadata = pd.read_csv(metadata_path)
print(f"âœ… Metadata loaded: {metadata.shape}")

# ============================================================
# 3ï¸âƒ£ Load TF-IDF Vectorizer & Text Features
# ============================================================
tfidf_vectorizer_path = os.path.join(FEATURE_DIR, "tfidf_vectorizer.pkl")
text_tfidf_path = os.path.join(FEATURE_DIR, "text_tfidf.pkl")

if os.path.exists(text_tfidf_path):
    print("ğŸ“‚ Loading precomputed text TF-IDF features...")
    text_features = joblib.load(text_tfidf_path)
    print(f"âœ… Text features loaded: {text_features.shape}")
else:
    if not os.path.exists(tfidf_vectorizer_path):
        raise FileNotFoundError(f"âŒ {tfidf_vectorizer_path} not found!")
    print("ğŸ“‚ Loading TF-IDF vectorizer...")
    vectorizer = joblib.load(tfidf_vectorizer_path)

    # Try to find a text column automatically
    text_col = None
    for col in metadata.columns:
        if metadata[col].dtype == "object" and metadata[col].str.len().mean() > 5:
            text_col = col
            break

    if text_col is None:
        raise ValueError("âŒ No suitable text column found in metadata.csv! Please check the file.")
    
    print(f"ğŸ“ Using text column: {text_col}")
    text_features = vectorizer.transform(metadata[text_col].fillna(""))
    print(f"âœ… Text features generated: {text_features.shape}")

# ============================================================
# Convert sparse to dense if needed
# ============================================================
if not isinstance(text_features, np.ndarray):
    text_features = text_features.toarray()  # csr_matrix â†’ dense
    print(f"âœ… Text features converted to dense: {text_features.shape}")

# ============================================================
# 4ï¸âƒ£ Load Sample IDs
# ============================================================
image_ids_path = os.path.join(FEATURE_DIR, "image_ids.csv")
if os.path.exists(image_ids_path):
    ids_df = pd.read_csv(image_ids_path)
    sample_ids = ids_df.iloc[:, 0].values  # assumes first column is ID
    print(f"âœ… Sample IDs loaded: {len(sample_ids)}")
else:
    sample_ids = np.arange(len(metadata))
    print(f"âš ï¸ image_ids.csv not found, using default IDs: {len(sample_ids)}")

# ============================================================
# 5ï¸âƒ£ Load the Trained Model (with custom_objects)
# ============================================================
if not os.path.exists(MODEL_PATH):
    raise FileNotFoundError(f"âŒ {MODEL_PATH} not found!")

print("ğŸ§  Loading trained hybrid model...")
model = load_model(MODEL_PATH, custom_objects={"mae": MeanAbsoluteError()})
print("âœ… Model loaded successfully.")

# ============================================================
# 6ï¸âƒ£ Generate Predictions
# ============================================================
print("ğŸ”® Generating predictions...")

# Match model input dimensions safely
expected_dim = model.input[1].shape[1]
if text_features.shape[1] != expected_dim:
    print(f"âš ï¸ Adjusting text feature dimensions from {text_features.shape[1]} â†’ {expected_dim}")
    new_text_features = np.zeros((text_features.shape[0], expected_dim))
    new_text_features[:, :text_features.shape[1]] = text_features
    text_features = new_text_features

predictions = model.predict([image_features, text_features], verbose=1)
predictions = predictions.flatten()
print(f"âœ… Predictions generated: {predictions.shape}")

# ============================================================
# 7ï¸âƒ£ Save Submission
# ============================================================
submission_path = r"Y:\ML_CHALLENGE_2025\ml-pricing-challenge\outputs\submission.csv"
submission = pd.DataFrame({
    "id": sample_ids,
    "price": predictions
})
submission.to_csv(submission_path, index=False)
print(f"ğŸ“ Submission saved as {submission_path} âœ…")
